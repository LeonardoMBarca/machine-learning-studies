{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '/Users/leona/OneDrive/Documentos/GitHub/machine-learning-studies/final_exercise/recipeData.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73861, 23)\n",
      "(35424, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_24672\\3551734408.py:19: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['SugarScale'] = df['SugarScale'].replace('Plato', 1)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(data, encoding='ISO-8859-1')\n",
    "print(df.shape)\n",
    "for style, count in df['StyleID'].value_counts().items():\n",
    "    if count < 1000:\n",
    "        df = df[df['StyleID'] != style]\n",
    "        \n",
    "for i, e in df.isna().sum().items():\n",
    "    if e > 20000:\n",
    "        df.drop(i, axis=1, inplace=True)\n",
    "\n",
    "df.fillna(df['PitchRate'].median(), inplace=True)\n",
    "for column, has_na in df.isna().any().items():\n",
    "    if has_na:\n",
    "        df.fillna(df[column].mean(), inplace=True)\n",
    "\n",
    "df.drop(columns=['URL', 'Name', 'BeerID', 'Style'], axis=1, inplace=True)\n",
    "\n",
    "df['SugarScale'] = df['SugarScale'].replace('Specific Gravity', 0)\n",
    "df['SugarScale'] = df['SugarScale'].replace('Plato', 1)\n",
    "df = pd.get_dummies(df, columns=['BrewMethod'], dtype=int)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns='StyleID', axis=1)\n",
    "y = df['StyleID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, roc_auc_score, log_loss, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['KNeighbors:', 0.48108616951457, 'Model: Logistic Regression, Score: 0.4668867391085182', 'Model: Gaussian, Score: 0.4111335413688824', 'Model: Decision Tree, Score: 0.4785454991757345']\n"
     ]
    }
   ],
   "source": [
    "def models(a, b):    \n",
    "    x = a\n",
    "    y = b\n",
    "    normalize = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_norm = normalize.fit_transform(x)\n",
    "    \n",
    "    strat = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(max_iter=1000, tol=0.1),\n",
    "        'Gaussian': GaussianNB(),\n",
    "        'Decision Tree': DecisionTreeClassifier()\n",
    "    }\n",
    "    \n",
    "    results = ['KNeighbors:', cross_val_score(KNeighborsClassifier(), x_norm, y, cv=strat, n_jobs=-1).mean()]\n",
    "    for name, model in models.items():\n",
    "        result = cross_val_score(model, x, y, cv=strat, n_jobs=-1)\n",
    "        results.append(f'Model: {name}, Score: {result.mean()}')\n",
    "    \n",
    "    print(results)\n",
    "models(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score of kneighborsclassifier was: 0.5001976061427281, with the best parameters: {'metric': 'minkowski', 'n_neighbors': 9, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "def neighbors(a, b):\n",
    "    x = a\n",
    "    y = b\n",
    "    \n",
    "    normalize = MinMaxScaler(feature_range=(0, 1))\n",
    "    x_norm = normalize.fit_transform(x)\n",
    "    \n",
    "    param_grid = {\n",
    "        'n_neighbors': np.array([3, 5, 7, 9]),\n",
    "        'metric': ['minkowski', 'chebyshev'],\n",
    "        'p': np.array([1, 2, 3])\n",
    "    }\n",
    "    \n",
    "    neighbors = KNeighborsClassifier()\n",
    "    grid = GridSearchCV(estimator=neighbors, param_grid=param_grid, cv=3, n_jobs=-1)\n",
    "    grid.fit(x_norm, y)\n",
    "    \n",
    "    print(f'The best score of kneighborsclassifier was: {grid.best_score_}, with the best parameters: {grid.best_params_}')\n",
    "neighbors(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score of DecisionTreeClassifier was: 0.5714485355091657, with the best parameters: {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 3}\n"
     ]
    }
   ],
   "source": [
    "def tree(a, b):\n",
    "    x = a\n",
    "    y = b\n",
    "    \n",
    "    strat = StratifiedKFold(n_splits=5)\n",
    "    \n",
    "    param_grid = {\n",
    "        'min_samples_split': np.array([3, 4, 5, 6, 7, 8, 9]),\n",
    "        'max_depth': np.array([3, 4, 5, 6]),\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    \n",
    "    tree = DecisionTreeClassifier()\n",
    "    grid = GridSearchCV(estimator=tree, param_grid=param_grid, cv=strat, n_jobs=-1)\n",
    "    grid.fit(x, y)\n",
    "    \n",
    "    print(f'The best score of DecisionTreeClassifier was: {grid.best_score_}, with the best parameters: {grid.best_params_}')\n",
    "tree(x, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
